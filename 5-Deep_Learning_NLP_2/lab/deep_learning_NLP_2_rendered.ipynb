{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introduction to basic sequence-to-sequence learning using a Long short term memory (LSTM) module.\n",
    "Given a string of characters representing a math problem \"3141+42\" we would like to generate a string of characters representing the correct solution: \"3183\". Our network will learn how to do basic mathematical operations.\n",
    "The important part is that we will not first use our human intelligence to break the string up into integers and a mathematical operator. We want the computer to figure all that out by itself.\n",
    "Each math problem is an input sequence: a list of {0,...,9} integers and math operation symbols\n",
    "The result of the operation (\"$3141+42$\" $\\rightarrow$ \"$3183$\"</span>) is the sequence to decode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**math_operators** is the set of $5$ operations we are going to use to build are input sequences.<br/>\n",
    "The math_expressions_generation function uses them to generate a large set of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def math_expressions_generation(n_samples=1000, n_digits=3, invert=True):\n",
    "    X, Y = [], []\n",
    "    math_operators = {\n",
    "        \"+\": operator.add,\n",
    "        \"-\": operator.sub,\n",
    "        \"*\": operator.mul,\n",
    "        \"/\": operator.truediv,\n",
    "        \"%\": operator.mod,\n",
    "    }\n",
    "    for i in range(n_samples):\n",
    "        a, b = np.random.randint(1, 10 ** n_digits, size=2)\n",
    "        op = np.random.choice(list(math_operators.keys()))\n",
    "        res = math_operators[op](a, b)\n",
    "        x = \"\".join([str(elem) for elem in (a, op, b)])\n",
    "        if invert is True:\n",
    "            x = x[::-1]\n",
    "        y = \"{:.5f}\".format(res) if isinstance(res, float) else str(res)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998%529 = 469\n",
      "168+795 = 963\n",
      "733*375 = 274875\n",
      "354-460 = -106\n",
      "435%253 = 182\n",
      "378+236 = 614\n",
      "188-295 = -107\n",
      "818%920 = 818\n",
      "140+333 = 473\n",
      "526%202 = 122\n",
      "394-83 = 311\n",
      "623+471 = 1094\n",
      "155/639 = 0.24257\n",
      "345%809 = 345\n",
      "465-865 = -400\n",
      "136/5 = 27.20000\n",
      "324+884 = 1208\n",
      "966/34 = 28.41176\n",
      "335*802 = 268670\n",
      "334%838 = 334\n"
     ]
    }
   ],
   "source": [
    "quick_for_debugg = False\n",
    "n_samples = 100 if quick_for_debugg else int(1e5)\n",
    "\n",
    "X, y = math_expressions_generation(n_samples=n_samples, n_digits=3, invert=True)\n",
    "for X_i, y_i in list(zip(X, y))[:20]:\n",
    "    print(X_i[::-1], \"=\", y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Encoder and decoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- encoder and decoder are both GRU models\n",
    "- encoder and decoder both take an input sequence and output $1$ hidden vector for each step in input sequence\n",
    "- the decoder also outputs $1$ softmax per step in input sequence, that corresponds to the next predicted token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells the example is:\n",
    "- sequence to encode: 94+8\n",
    "- sequence to decode: $102\\text{<EOS>}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB: In this TP all tensors have a $\\text{batch_size}$ axis in addition to the traditional $\\text{nb_timesteps, vector_dim}$ axes.**\n",
    "\n",
    "**The batch size axis is there because pytorch GRU (and most other pytorch layers) can process tensors organized in batch, meaning that contain several sequences.**\n",
    "\n",
    "**In the returned tensor, the results for each sequence are given along a batch axis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**encoder and decoder inputs**\n",
    "- for the encoder, the input sequence is the operation: $94+8$\n",
    "\n",
    "<img src=\"../images/encoder_input.png\" style=\"width: 600px;\" />\n",
    "\n",
    "- for the decoder, if using teacher forcing, the input sequence is the off-set of the sequence to decode: $\\text{<GO>}102$\n",
    "\n",
    "<img src=\"../images/decoder_input_all.png\" style=\"width: 600px;\" />\n",
    "\n",
    "- for the decoder, if **not** using teacher forcing, the input sequence is $1$ timestep long and is either the $\\text{<GO>}$ token or the previous predicted token:\n",
    "\n",
    "<img src=\"../images/decoder_input_one.png\" style=\"width: 600px;\" />\n",
    "\n",
    "for the decoder those $3$ scenarios are one: the input sequence is of shape $(\\text{nb_timesteps, batch_size, input_dim})$, the decoder goes through all timesteps for each sequence, produces $1$ hidden vector and $1$ prediction per timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no attention vs attention**\n",
    "\n",
    "the attention mechanism is handled (and implemented) at the decoder level\n",
    "\n",
    "**no attention**\n",
    "\n",
    "<img src=\"../images/decoder_no_attention_all.png\" style=\"width: 900px;\" />\n",
    "\n",
    "At each timestep, the hidden vector is used to predict the next token\n",
    "\n",
    "\n",
    "**attention**\n",
    "\n",
    "<img src=\"../images/decoder_attention_all.png\" style=\"width: 900px;\" />\n",
    "\n",
    "The attention mechanism here is of type that is performed over the decoder hidden vectors after they are produced.\n",
    "- For each timestep of the decoder input, similarity between the decoder hidden vector and all the encoder hidden vectors is computed. It allows to determine which token in encoder input to focus on. Here similarity is just a dot product $hdec^T \\cdot henc$ between the vectors.\n",
    "- For each timestep of the decoder input, pass this \"attention weights\" vector to a softmax so the weights sum to $1$.\n",
    "- For each timestep of the decoder input, compute a weighted sum of the encoder hidden vectors. This is the context vector. The fact that it is more or less heavily weighted towards certain encoder hidden vector relates to the tokens the algorithm focuses on.\n",
    "- Use the context vector to predict the next token by performing a matrix product to set at the right dimension and apply a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size).to(self.device)\n",
    "\n",
    "    def forward(self, encoder_input, henc_init=None):\n",
    "        if henc_init is None:\n",
    "            henc_init = torch.zeros(\n",
    "                1, encoder_input.size()[1], self.hidden_size, device=self.device\n",
    "            ).to(self.device)\n",
    "        henc_ts, henc_final = self.gru(encoder_input, henc_init)\n",
    "        return henc_ts, henc_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, device, attention=False):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(output_size, hidden_size).to(self.device)\n",
    "        self.linear = nn.Linear(hidden_size, output_size).to(self.device)\n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, decoder_input, hdec_init, henc_ts=None):\n",
    "\n",
    "        hdec_ts, hdec_final = self.gru(decoder_input, hdec_init)\n",
    "        if self.attention:\n",
    "            assert henc_ts is not None\n",
    "            # (ts_dec, batch, dim) to (batch, ts_dec, dim)\n",
    "            hdec_ts = hdec_ts.permute(1, 0, 2)\n",
    "            # (ts_enc, batch, dim) to (batch, dim, ts_enc)\n",
    "            henc_ts = henc_ts.permute(1, 2, 0)\n",
    "            # (batch, ts_dec, ts_enc)\n",
    "            attn_weights_dec_to_enc = torch.bmm(hdec_ts, henc_ts)\n",
    "            # (batch, ts_dec, ts_enc) to (ts_dec, batch, ts_enc)\n",
    "            attn_weights_dec_to_enc = attn_weights_dec_to_enc.permute(1, 0, 2)\n",
    "            # (batch, dim, ts_enc) to (batch, ts_enc, dim)\n",
    "            henc_ts = henc_ts.permute(0, 2, 1)\n",
    "            attn_weights_dec_to_enc = F.softmax(attn_weights_dec_to_enc, dim=2)\n",
    "            # (batch, ts_enc, dim) to (ts_dec, batch, ts_enc, dim)\n",
    "            henc_ts = henc_ts.unsqueeze(0).repeat(\n",
    "                attn_weights_dec_to_enc.size()[0], 1, 1, 1\n",
    "            )\n",
    "            # (ts_dec, batch, ts_enc) to (ts_dec, batch, ts_enc, 1)\n",
    "            attn_weights_dec_to_enc = attn_weights_dec_to_enc.unsqueeze(3)\n",
    "            # (ts_dec, batch, ts_enc, 1) x (ts_dec, batch, ts_enc, dim) --> (ts_dec, batch, ts_enc, dim)\n",
    "            context_vectors = attn_weights_dec_to_enc * henc_ts\n",
    "            # (ts_dec, batch, ts_enc, dim) to (ts_dec, batch, dim)\n",
    "            context_vectors = context_vectors.sum(2)\n",
    "            output = F.log_softmax(self.linear(context_vectors), dim=2)\n",
    "        else:\n",
    "            output = F.log_softmax(self.linear(hdec_ts), dim=2)\n",
    "        return output, hdec_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Sequence to sequence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GO** is the character (\"=\") that marks the beginning of decoding for the decoder GRU<br/>\n",
    "**EOS** is the character (\"\\n\") that marks the end of sequence to decode for the decoder GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**global Seq2seq architecture (teacher forcing scenario)**\n",
    "\n",
    "<img src=\"../images/seq2seq_teacher.png\" style=\"width: 1000px;\" />\n",
    "\n",
    "the teacher forcing mechanism is handled (and implemented) at the seq2seq forward pass level.\n",
    "\n",
    "teacher forcing or no teacher forcing depends on the kind of input passed to the decoder.\n",
    "\n",
    "**teacher forcing**\n",
    "\n",
    "<img src=\"../images/teacher_forcing.png\" style=\"width: 600px;\" />\n",
    "\n",
    "- the decoder input is the sequence of expected decoded tokens at all timesteps.\n",
    "- the decoder input is passed in one go to the decoder. The decoder goes through all timesteps and decodes the whole sequence in one go.\n",
    "- the decoder input is of shape $(\\text{nb_timesteps, batch_size, input_dim})$.\n",
    "\n",
    "**no teacher forcing**\n",
    "\n",
    "<img src=\"../images/no_teacher_forcing.png\" style=\"width: 1000px;\" />\n",
    "\n",
    "- the decoder input is $1$ timestep long and either the $\\text{GO}$ token or the previous decoded token\n",
    "- the decoder inputs are passed iteratively in many stages to the decoder. For each stage, the decoder is given as state the previous returned hidden vector and take as input the previous decoded token. It produces a new hidden vector and decoded token that are returned for the next stage.\n",
    "- the decoder input for each stage is of shape $(\\text{1, batch_size, input_dim})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(\n",
    "        self, X, y, hidden_size=256, learning_rate=0.01, attention=False\n",
    "    ):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.GO = \"=\"\n",
    "        self.EOS = \"\\n\"\n",
    "        self.dataset_size = None\n",
    "        self.encoder_char_index = None\n",
    "        self.encoder_index_char = None\n",
    "        self.decoder_char_index = None\n",
    "        self.decoder_index_char = None\n",
    "        self.encoder_vocabulary_size = None\n",
    "        self.decoder_vocabulary_size = None\n",
    "        self.max_encoder_sequence_length = None\n",
    "        self.max_decoder_sequence_length = None\n",
    "        self.encoder_input_tr = None\n",
    "        self.encoder_input_val = None\n",
    "        self.decoder_input_tr = None\n",
    "        self.decoder_input_val = None\n",
    "        self.target_tr = None\n",
    "        self.target_val = None\n",
    "        self._set_data_properties_attributes()\n",
    "        self._construct_data_set()\n",
    "        self.encoder = EncoderRNN(\n",
    "            input_size=self.encoder_vocabulary_size,\n",
    "            hidden_size=hidden_size,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.decoder = DecoderRNN(\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=self.decoder_vocabulary_size,\n",
    "            attention=attention,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.parameters = list(self.encoder.parameters()) + list(\n",
    "            self.decoder.parameters()\n",
    "        )\n",
    "        self.optimizer = optim.Adam(self.parameters, lr=learning_rate)\n",
    "        self.criterion = nn.NLLLoss(reduction=\"mean\")\n",
    "        # training attributes\n",
    "        self.total_loss = None\n",
    "        self.total_loss_nb_samples = None\n",
    "\n",
    "    def _set_data_properties_attributes(self):\n",
    "        self.y = list(map(lambda token: self.GO + token + self.EOS, self.y))\n",
    "        self.dataset_size = len(self.X)\n",
    "        encoder_characters = sorted(list(set(\"\".join(self.X))))\n",
    "        decoder_characters = sorted(list(set(\"\".join(self.y))))\n",
    "        decoder_characters.remove(self.EOS)\n",
    "        # set EOS at 0 index so argmax on zero vector falls at EOS\n",
    "        decoder_characters = [self.EOS] + decoder_characters\n",
    "        self.encoder_char_index = dict((c, i) for i, c in enumerate(encoder_characters))\n",
    "        self.encoder_index_char = dict((i, c) for i, c in enumerate(encoder_characters))\n",
    "        self.decoder_char_index = dict((c, i) for i, c in enumerate(decoder_characters))\n",
    "        self.decoder_index_char = dict((i, c) for i, c in enumerate(decoder_characters))\n",
    "        self.encoder_vocabulary_size = len(self.encoder_char_index)\n",
    "        self.decoder_vocabulary_size = len(self.decoder_char_index)\n",
    "        self.max_encoder_sequence_length = max([len(sequence) for sequence in self.X])\n",
    "        self.max_decoder_sequence_length = max([len(sequence) for sequence in self.y])\n",
    "        print(\"Number of samples:\", self.dataset_size)\n",
    "        print(\"Number of unique encoder tokens:\", self.encoder_vocabulary_size)\n",
    "        print(\"Number of unique decoder tokens:\", self.decoder_vocabulary_size)\n",
    "        print(\"Max sequence length for encoding:\", self.max_encoder_sequence_length)\n",
    "        print(\"Max sequence length for decoding:\", self.max_decoder_sequence_length)\n",
    "\n",
    "    def _construct_data_set(self):\n",
    "        encoder_input = torch.zeros(\n",
    "            (\n",
    "                self.max_encoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.encoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        decoder_input = torch.zeros(\n",
    "            (\n",
    "                self.max_decoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.decoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        target = torch.zeros(\n",
    "            (\n",
    "                self.max_decoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.decoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        for i, (X_i, y_i) in enumerate(zip(self.X, self.y)):\n",
    "            for t, char in enumerate(X_i):\n",
    "                encoder_input[t, i, self.encoder_char_index[char]] = 1.0\n",
    "            for t, char in enumerate(y_i):\n",
    "                decoder_input[t, i, self.decoder_char_index[char]] = 1.0\n",
    "                if t > 0:\n",
    "                    target[t - 1, i, self.decoder_char_index[char]] = 1.0\n",
    "\n",
    "        p_val = 0.25\n",
    "        size_val = int(p_val * self.dataset_size)\n",
    "        idxs = np.arange(self.dataset_size)\n",
    "        np.random.shuffle(idxs)\n",
    "        idxs_tr = idxs[:-size_val]\n",
    "        idxs_val = idxs[-size_val:]\n",
    "        (\n",
    "            self.encoder_input_tr,\n",
    "            self.encoder_input_val,\n",
    "            self.decoder_input_tr,\n",
    "            self.decoder_input_val,\n",
    "            self.target_tr,\n",
    "            self.target_val,\n",
    "        ) = (\n",
    "            encoder_input[:, idxs_tr, :],\n",
    "            encoder_input[:, idxs_val, :],\n",
    "            decoder_input[:, idxs_tr, :],\n",
    "            decoder_input[:, idxs_val, :],\n",
    "            target[:, idxs_tr, :],\n",
    "            target[:, idxs_val, :],\n",
    "        )\n",
    "        self.encoder_input_tr = self.encoder_input_tr.to(self.device)\n",
    "        self.encoder_input_val = self.encoder_input_val.to(self.device)\n",
    "        self.decoder_input_tr = self.decoder_input_tr.to(self.device)\n",
    "        self.decoder_input_val = self.decoder_input_val.to(self.device)\n",
    "        self.target_tr = self.target_tr.to(self.device)\n",
    "        self.target_val = self.target_val.to(self.device)\n",
    "\n",
    "    def forward(\n",
    "        self, encoder_input, decoder_input=None, teacher_enforce=True, inference=False\n",
    "    ):\n",
    "\n",
    "        batch_size = encoder_input.size()[1]\n",
    "        if inference:\n",
    "            assert (\n",
    "                batch_size == 1\n",
    "            ), \"during inference batch size must be 1: 1 sequence processed\"\n",
    "            if teacher_enforce:\n",
    "                print(\"Warning teacher_enforce will be set to False for inference\")\n",
    "                teacher_enforce = False\n",
    "\n",
    "        henc_ts, henc_final = self.encoder(encoder_input)\n",
    "\n",
    "        if teacher_enforce:\n",
    "            assert decoder_input is not None\n",
    "            pred_softmax_all_ts, hdec_final = self.decoder(\n",
    "                decoder_input,\n",
    "                hdec_init=henc_final,\n",
    "                henc_ts=henc_ts if self.decoder.attention else None,\n",
    "            )\n",
    "\n",
    "        elif not teacher_enforce:\n",
    "            pred_softmax_all_ts = []\n",
    "            decoder_input = torch.zeros(1, batch_size, self.decoder_vocabulary_size)\n",
    "            decoder_input[0, :, self.decoder_char_index[self.GO]] = 1\n",
    "            decoder_input = decoder_input.to(self.device)\n",
    "            hdec_init = henc_final\n",
    "            # iterate over all decoder stages\n",
    "            for _ in range(self.max_decoder_sequence_length):\n",
    "                pred_softmax, hdec_final = self.decoder(\n",
    "                    decoder_input,\n",
    "                    hdec_init=hdec_init,\n",
    "                    henc_ts=henc_ts if self.decoder.attention else None,\n",
    "                )\n",
    "                pred_softmax_all_ts.append(pred_softmax)\n",
    "                # convert softmax predictions to idx\n",
    "                preds_idx = pred_softmax.argmax(dim=2)\n",
    "                # convert idx predictions to one-hot encoding\n",
    "                decoder_input = torch.zeros(1, batch_size, self.decoder_vocabulary_size)\n",
    "                decoder_input = decoder_input.to(self.device)\n",
    "                decoder_input[0, np.arange(batch_size), preds_idx] = 1\n",
    "\n",
    "                hdec_init = hdec_final\n",
    "                if inference:\n",
    "                    pred = preds_idx.squeeze().item()\n",
    "                    if pred == self.decoder_char_index[self.EOS]:\n",
    "                        break\n",
    "            pred_softmax_all_ts = torch.cat(pred_softmax_all_ts)\n",
    "\n",
    "        return pred_softmax_all_ts\n",
    "\n",
    "    def _train_on_batch(\n",
    "        self, encoder_input, target, teacher_forcing, decoder_input=None\n",
    "    ):\n",
    "        self.optimizer.zero_grad()\n",
    "        prediction = self.forward(\n",
    "            encoder_input, decoder_input=decoder_input, teacher_enforce=teacher_forcing\n",
    "        )\n",
    "        target_idx = target.argmax(2)\n",
    "        loss_on_batch = self.criterion(\n",
    "            prediction.reshape(-1, prediction.size()[2]), target_idx.reshape(-1)\n",
    "        )\n",
    "        loss_on_batch.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss_on_batch\n",
    "\n",
    "    def train(self, nb_epoch=10, batch_size=64, teacher_enforce=True):\n",
    "        arr = np.arange(self.encoder_input_tr.size()[1])\n",
    "        np.random.shuffle(arr)\n",
    "        nb_batch = int(self.encoder_input_tr.size()[1] / batch_size)\n",
    "        verbose_every = 5 if nb_batch >= 5 else 1\n",
    "\n",
    "        for epoch in range(nb_epoch):\n",
    "            self._reset_monitor_train_epoch()\n",
    "            if epoch > 0:\n",
    "                print()\n",
    "            for batch_idx in range(nb_batch):\n",
    "                idxs = arr[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "                encoder_input_batch_tr = self.encoder_input_tr[:, idxs, :]\n",
    "                target_batch_tr = self.target_tr[:, idxs, :]\n",
    "                decoder_input_batch_tr = self.decoder_input_tr[:, idxs, :]\n",
    "\n",
    "                batch_loss_tr = self._train_on_batch(\n",
    "                    encoder_input_batch_tr,\n",
    "                    target_batch_tr,\n",
    "                    teacher_forcing=teacher_enforce,\n",
    "                    decoder_input=decoder_input_batch_tr,\n",
    "                )\n",
    "                self._monitor_train_epoch(\n",
    "                    batch_loss=batch_loss_tr,\n",
    "                    batch_size=encoder_input_batch_tr.size()[1],\n",
    "                )\n",
    "\n",
    "                if (batch_idx + 1) % verbose_every == 0:\n",
    "                    self._display_training(\n",
    "                        epoch, nb_epoch, batch_idx, nb_batch, epoch_ended=False\n",
    "                    )\n",
    "\n",
    "            self._monitor_validation(teacher_enforce=teacher_enforce)\n",
    "            self._display_training(\n",
    "                epoch, nb_epoch, batch_idx, nb_batch, epoch_ended=True\n",
    "            )\n",
    "\n",
    "    def _monitor_train_epoch(self, batch_loss, batch_size):\n",
    "        self.total_loss += batch_loss * batch_size\n",
    "        self.total_loss_nb_samples += batch_size\n",
    "\n",
    "    def _reset_monitor_train_epoch(self):\n",
    "        self.total_loss = 0\n",
    "        self.total_loss_nb_samples = 0\n",
    "\n",
    "    def _monitor_validation(self, teacher_enforce):\n",
    "\n",
    "        prediction_val = self(\n",
    "            self.encoder_input_val,\n",
    "            decoder_input=self.decoder_input_val,\n",
    "            teacher_enforce=teacher_enforce,\n",
    "        )\n",
    "        target_val_idx = self.target_val.argmax(2)\n",
    "        self.last_loss_val = self.criterion(\n",
    "            prediction_val.reshape(-1, prediction_val.size()[2]),\n",
    "            target_val_idx.reshape(-1),\n",
    "        )\n",
    "\n",
    "    def _display_training(\n",
    "        self, epoch, nb_epoch, idx_batch, nb_batch, epoch_ended=False\n",
    "    ):\n",
    "        msg = \"Epoch {}/{} {} {}\".format(\n",
    "            epoch + 1,\n",
    "            nb_epoch,\n",
    "            utils.arrow(idx_batch + 1, nb_batch),\n",
    "            \" mean loss: %.5f\" % (self.total_loss.item() / self.total_loss_nb_samples),\n",
    "        )\n",
    "        if epoch_ended:\n",
    "            msg += \" val loss: %.5f\" % self.last_loss_val\n",
    "        print(msg, end=\"\\r\")\n",
    "\n",
    "    def _tensor_to_words(self, output, decoded=True):\n",
    "        dict_index_char = (\n",
    "            self.decoder_index_char if decoded else self.encoder_index_char\n",
    "        )\n",
    "        pred_idx = output.argmax(dim=2)\n",
    "        decoded_words = []\n",
    "        for seq in range(pred_idx.size()[1]):\n",
    "            idxs_chars = pred_idx[:, seq]\n",
    "            decoded_word = \"\".join(dict_index_char[idx.item()] for idx in idxs_chars)\n",
    "            if not decoded:\n",
    "                # correct errors due to zero vectors at the end\n",
    "                accepted_end_chars = set(list(\"0123456789\"))\n",
    "                for i in range(len(decoded_word) - 1, -1, -1):\n",
    "                    if decoded_word[i] in accepted_end_chars:\n",
    "                        decoded_word = decoded_word[: i + 1]\n",
    "                        break\n",
    "            decoded_words.append(decoded_word)\n",
    "        return decoded_words\n",
    "    \n",
    "    def evaluate(self, nb=30):\n",
    "        nb = min(nb, self.encoder_input_val.size()[1])\n",
    "        for i in range(nb):\n",
    "            output = self(\n",
    "                self.encoder_input_val[:, i : i + 1, :],\n",
    "                inference=True,\n",
    "                teacher_enforce=False\n",
    "            )\n",
    "            decoded_word = self._tensor_to_words(output, decoded=True)[0]\n",
    "            operation = self._tensor_to_words(\n",
    "                self.encoder_input_val[:, i : i + 1, :], decoded=False\n",
    "            )[0][::-1]\n",
    "            expected_decoded_word = self._tensor_to_words(\n",
    "                self.target_val[:, i : i + 1, :], decoded=True\n",
    "            )[0]\n",
    "            decoded_word = decoded_word.replace(\"\\n\", \"\")\n",
    "            operation = operation.replace(\"\\n\", \"\")\n",
    "            expected_decoded_word = expected_decoded_word.replace(\"\\n\", \"\")\n",
    "            print(\n",
    "                \"Input sentence: {} Decoded sentence: {} Expected decoded sentence: {}\".format(\n",
    "                    operation, decoded_word, expected_decoded_word\n",
    "                )\n",
    "            )\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no attention - teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2seq(X, y, hidden_size=128, attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 ==================================================>  mean loss: 0.77045 val loss: 0.62896\n",
      "Epoch 2/3 ==================================================>  mean loss: 0.58779 val loss: 0.56336\n",
      "Epoch 3/3 ==================================================>  mean loss: 0.54589 val loss: 0.52829\r"
     ]
    }
   ],
   "source": [
    "seq2seq.train(nb_epoch=3, batch_size=64, teacher_enforce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 431%156 Decoded sentence: 117 Expected decoded sentence: 119\n",
      "\n",
      "Input sentence: 95-444 Decoded sentence: -371 Expected decoded sentence: -349\n",
      "\n",
      "Input sentence: 526/266 Decoded sentence: 2.05000 Expected decoded sentence: 1.97744\n",
      "\n",
      "Input sentence: 408/219 Decoded sentence: 1.98339 Expected decoded sentence: 1.86301\n",
      "\n",
      "Input sentence: 95-763 Decoded sentence: -662 Expected decoded sentence: -668\n",
      "\n",
      "Input sentence: 155/132 Decoded sentence: 1.15000 Expected decoded sentence: 1.17424\n",
      "\n",
      "Input sentence: 507%31 Decoded sentence: 14 Expected decoded sentence: 11\n",
      "\n",
      "Input sentence: 762/720 Decoded sentence: 1.10000 Expected decoded sentence: 1.05833\n",
      "\n",
      "Input sentence: 10-507 Decoded sentence: -527 Expected decoded sentence: -497\n",
      "\n",
      "Input sentence: 836/826 Decoded sentence: 1.02527 Expected decoded sentence: 1.01211\n",
      "\n",
      "Input sentence: 951*199 Decoded sentence: 183919 Expected decoded sentence: 189249\n",
      "\n",
      "Input sentence: 319*36 Decoded sentence: 10396 Expected decoded sentence: 11484\n",
      "\n",
      "Input sentence: 872*823 Decoded sentence: 662394 Expected decoded sentence: 717656\n",
      "\n",
      "Input sentence: 961-365 Decoded sentence: 614 Expected decoded sentence: 596\n",
      "\n",
      "Input sentence: 795+979 Decoded sentence: 1734 Expected decoded sentence: 1774\n",
      "\n",
      "Input sentence: 126-873 Decoded sentence: -771 Expected decoded sentence: -747\n",
      "\n",
      "Input sentence: 543+757 Decoded sentence: 1284 Expected decoded sentence: 1300\n",
      "\n",
      "Input sentence: 762*792 Decoded sentence: 582184 Expected decoded sentence: 603504\n",
      "\n",
      "Input sentence: 422*918 Decoded sentence: 390216 Expected decoded sentence: 387396\n",
      "\n",
      "Input sentence: 221/208 Decoded sentence: 0.96111 Expected decoded sentence: 1.06250\n",
      "\n",
      "Input sentence: 499*671 Decoded sentence: 335891 Expected decoded sentence: 334829\n",
      "\n",
      "Input sentence: 422/587 Decoded sentence: 0.73339 Expected decoded sentence: 0.71891\n",
      "\n",
      "Input sentence: 638/120 Decoded sentence: 5.10000 Expected decoded sentence: 5.31667\n",
      "\n",
      "Input sentence: 339+371 Decoded sentence: 712 Expected decoded sentence: 710\n",
      "\n",
      "Input sentence: 379/62 Decoded sentence: 5.10000 Expected decoded sentence: 6.11290\n",
      "\n",
      "Input sentence: 619-54 Decoded sentence: 527 Expected decoded sentence: 565\n",
      "\n",
      "Input sentence: 553%352 Decoded sentence: 141 Expected decoded sentence: 201\n",
      "\n",
      "Input sentence: 3-594 Decoded sentence: -599 Expected decoded sentence: -591\n",
      "\n",
      "Input sentence: 762%676 Decoded sentence: 122 Expected decoded sentence: 86\n",
      "\n",
      "Input sentence: 64-305 Decoded sentence: -279 Expected decoded sentence: -241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no attention - no teacher forcing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2seq(X, y, hidden_size=128, attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 ==================================================>  mean loss: 0.83080 val loss: 0.67193\n",
      "Epoch 2/3 ==================================================>  mean loss: 0.64011 val loss: 0.62522\n",
      "Epoch 3/3 ==================================================>  mean loss: 0.61004 val loss: 0.60270\r"
     ]
    }
   ],
   "source": [
    "seq2seq.train(nb_epoch=3, batch_size=64, teacher_enforce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 555%26 Decoded sentence: 31 Expected decoded sentence: 9\n",
      "\n",
      "Input sentence: 425*242 Decoded sentence: 101520 Expected decoded sentence: 102850\n",
      "\n",
      "Input sentence: 457/901 Decoded sentence: 0.43334 Expected decoded sentence: 0.50721\n",
      "\n",
      "Input sentence: 969%852 Decoded sentence: 13 Expected decoded sentence: 117\n",
      "\n",
      "Input sentence: 747*597 Decoded sentence: 433371 Expected decoded sentence: 445959\n",
      "\n",
      "Input sentence: 538+770 Decoded sentence: 1222 Expected decoded sentence: 1308\n",
      "\n",
      "Input sentence: 867-879 Decoded sentence: -72 Expected decoded sentence: -12\n",
      "\n",
      "Input sentence: 507+635 Decoded sentence: 1132 Expected decoded sentence: 1142\n",
      "\n",
      "Input sentence: 553/791 Decoded sentence: 0.73334 Expected decoded sentence: 0.69912\n",
      "\n",
      "Input sentence: 767+859 Decoded sentence: 1632 Expected decoded sentence: 1626\n",
      "\n",
      "Input sentence: 508+276 Decoded sentence: 832 Expected decoded sentence: 784\n",
      "\n",
      "Input sentence: 720-749 Decoded sentence: -11 Expected decoded sentence: -29\n",
      "\n",
      "Input sentence: 2/953 Decoded sentence: 0.00432 Expected decoded sentence: 0.00210\n",
      "\n",
      "Input sentence: 876*939 Decoded sentence: 833332 Expected decoded sentence: 822564\n",
      "\n",
      "Input sentence: 883/671 Decoded sentence: 1.30332 Expected decoded sentence: 1.31595\n",
      "\n",
      "Input sentence: 652*89 Decoded sentence: 53332 Expected decoded sentence: 58028\n",
      "\n",
      "Input sentence: 686-967 Decoded sentence: -333 Expected decoded sentence: -281\n",
      "\n",
      "Input sentence: 634%713 Decoded sentence: 634 Expected decoded sentence: 634\n",
      "\n",
      "Input sentence: 199+691 Decoded sentence: 930 Expected decoded sentence: 890\n",
      "\n",
      "Input sentence: 267-609 Decoded sentence: -332 Expected decoded sentence: -342\n",
      "\n",
      "Input sentence: 763*224 Decoded sentence: 153332 Expected decoded sentence: 170912\n",
      "\n",
      "Input sentence: 559+188 Decoded sentence: 715 Expected decoded sentence: 747\n",
      "\n",
      "Input sentence: 910/986 Decoded sentence: 0.03330 Expected decoded sentence: 0.92292\n",
      "\n",
      "Input sentence: 840+979 Decoded sentence: 1801 Expected decoded sentence: 1819\n",
      "\n",
      "Input sentence: 617-221 Decoded sentence: 334 Expected decoded sentence: 396\n",
      "\n",
      "Input sentence: 549%248 Decoded sentence: 10 Expected decoded sentence: 53\n",
      "\n",
      "Input sentence: 988-532 Decoded sentence: 434 Expected decoded sentence: 456\n",
      "\n",
      "Input sentence: 734-300 Decoded sentence: 444 Expected decoded sentence: 434\n",
      "\n",
      "Input sentence: 549/777 Decoded sentence: 0.74334 Expected decoded sentence: 0.70656\n",
      "\n",
      "Input sentence: 347%941 Decoded sentence: 347 Expected decoded sentence: 347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention - teacher forcing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn = Seq2seq(X, y, hidden_size=128, attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 ==================================================>  mean loss: 0.91747 val loss: 0.80604\n",
      "Epoch 2/3 ==================================================>  mean loss: 0.75058 val loss: 0.70789\n",
      "Epoch 3/3 ==================================================>  mean loss: 0.69090 val loss: 0.66158\r"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.train(nb_epoch=3, batch_size=64, teacher_enforce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 960+704 Decoded sentence: 1446 Expected decoded sentence: 1664\n",
      "\n",
      "Input sentence: 829*455 Decoded sentence: 344445 Expected decoded sentence: 377195\n",
      "\n",
      "Input sentence: 744+178 Decoded sentence: 948 Expected decoded sentence: 922\n",
      "\n",
      "Input sentence: 543*980 Decoded sentence: 555500 Expected decoded sentence: 532140\n",
      "\n",
      "Input sentence: 381-618 Decoded sentence: -243 Expected decoded sentence: -237\n",
      "\n",
      "Input sentence: 175+372 Decoded sentence: 333 Expected decoded sentence: 547\n",
      "\n",
      "Input sentence: 1/949 Decoded sentence: 0.04444 Expected decoded sentence: 0.00105\n",
      "\n",
      "Input sentence: 9*39 Decoded sentence: 2449 Expected decoded sentence: 351\n",
      "\n",
      "Input sentence: 556+629 Decoded sentence: 1147 Expected decoded sentence: 1185\n",
      "\n",
      "Input sentence: 246-167 Decoded sentence: 103 Expected decoded sentence: 79\n",
      "\n",
      "Input sentence: 970*878 Decoded sentence: 750000 Expected decoded sentence: 851660\n",
      "\n",
      "Input sentence: 680*248 Decoded sentence: 144400 Expected decoded sentence: 168640\n",
      "\n",
      "Input sentence: 399*703 Decoded sentence: 244447 Expected decoded sentence: 280497\n",
      "\n",
      "Input sentence: 335+787 Decoded sentence: 1144 Expected decoded sentence: 1122\n",
      "\n",
      "Input sentence: 215/253 Decoded sentence: 1.14444 Expected decoded sentence: 0.84980\n",
      "\n",
      "Input sentence: 45+827 Decoded sentence: 944 Expected decoded sentence: 872\n",
      "\n",
      "Input sentence: 138/183 Decoded sentence: 1.14444 Expected decoded sentence: 0.75410\n",
      "\n",
      "Input sentence: 36+222 Decoded sentence: 248 Expected decoded sentence: 258\n",
      "\n",
      "Input sentence: 907*535 Decoded sentence: 644445 Expected decoded sentence: 485245\n",
      "\n",
      "Input sentence: 764-108 Decoded sentence: 348 Expected decoded sentence: 656\n",
      "\n",
      "Input sentence: 508*354 Decoded sentence: 144448 Expected decoded sentence: 179832\n",
      "\n",
      "Input sentence: 926*484 Decoded sentence: 344444 Expected decoded sentence: 448184\n",
      "\n",
      "Input sentence: 611+897 Decoded sentence: 1444 Expected decoded sentence: 1508\n",
      "\n",
      "Input sentence: 167%659 Decoded sentence: 167 Expected decoded sentence: 167\n",
      "\n",
      "Input sentence: 774-485 Decoded sentence: 239 Expected decoded sentence: 289\n",
      "\n",
      "Input sentence: 99*504 Decoded sentence: 34444 Expected decoded sentence: 49896\n",
      "\n",
      "Input sentence: 576+147 Decoded sentence: 943 Expected decoded sentence: 723\n",
      "\n",
      "Input sentence: 364/488 Decoded sentence: 0.45545 Expected decoded sentence: 0.74590\n",
      "\n",
      "Input sentence: 363-187 Decoded sentence: 104 Expected decoded sentence: 176\n",
      "\n",
      "Input sentence: 464*884 Decoded sentence: 444446 Expected decoded sentence: 410176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention - no teacher forcing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn = Seq2seq(X, y, hidden_size=128, attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 ==================================================>  mean loss: 0.94894 val loss: 0.85740\n",
      "Epoch 2/3 ==================================================>  mean loss: 0.83816 val loss: 0.80700\n",
      "Epoch 3/3 ==================================================>  mean loss: 0.78547 val loss: 0.75858\r"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.train(nb_epoch=3, batch_size=64, teacher_enforce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 976-647 Decoded sentence: 169 Expected decoded sentence: 329\n",
      "\n",
      "Input sentence: 340/474 Decoded sentence: 0.61666 Expected decoded sentence: 0.71730\n",
      "\n",
      "Input sentence: 576%420 Decoded sentence: 10 Expected decoded sentence: 156\n",
      "\n",
      "Input sentence: 996+93 Decoded sentence: 1055 Expected decoded sentence: 1089\n",
      "\n",
      "Input sentence: 836-439 Decoded sentence: 299 Expected decoded sentence: 397\n",
      "\n",
      "Input sentence: 478-882 Decoded sentence: -316 Expected decoded sentence: -404\n",
      "\n",
      "Input sentence: 832-635 Decoded sentence: 155 Expected decoded sentence: 197\n",
      "\n",
      "Input sentence: 533%312 Decoded sentence: 11 Expected decoded sentence: 221\n",
      "\n",
      "Input sentence: 415%987 Decoded sentence: 305 Expected decoded sentence: 415\n",
      "\n",
      "Input sentence: 758/46 Decoded sentence: 10.00000 Expected decoded sentence: 16.47826\n",
      "\n",
      "Input sentence: 297%183 Decoded sentence: 15 Expected decoded sentence: 114\n",
      "\n",
      "Input sentence: 247/434 Decoded sentence: 0.55555 Expected decoded sentence: 0.56912\n",
      "\n",
      "Input sentence: 455/215 Decoded sentence: 2.55555 Expected decoded sentence: 2.11628\n",
      "\n",
      "Input sentence: 467+892 Decoded sentence: 1258 Expected decoded sentence: 1359\n",
      "\n",
      "Input sentence: 71+195 Decoded sentence: 366 Expected decoded sentence: 266\n",
      "\n",
      "Input sentence: 526/367 Decoded sentence: 1.56666 Expected decoded sentence: 1.43324\n",
      "\n",
      "Input sentence: 212%922 Decoded sentence: 211 Expected decoded sentence: 212\n",
      "\n",
      "Input sentence: 676/463 Decoded sentence: 1.35555 Expected decoded sentence: 1.46004\n",
      "\n",
      "Input sentence: 762/471 Decoded sentence: 1.15655 Expected decoded sentence: 1.61783\n",
      "\n",
      "Input sentence: 713%195 Decoded sentence: 12 Expected decoded sentence: 128\n",
      "\n",
      "Input sentence: 602/167 Decoded sentence: 2.55555 Expected decoded sentence: 3.60479\n",
      "\n",
      "Input sentence: 844/528 Decoded sentence: 1.35555 Expected decoded sentence: 1.59848\n",
      "\n",
      "Input sentence: 478+976 Decoded sentence: 1255 Expected decoded sentence: 1454\n",
      "\n",
      "Input sentence: 511+367 Decoded sentence: 966 Expected decoded sentence: 878\n",
      "\n",
      "Input sentence: 304*943 Decoded sentence: 259596 Expected decoded sentence: 286672\n",
      "\n",
      "Input sentence: 681/408 Decoded sentence: 1.35555 Expected decoded sentence: 1.66912\n",
      "\n",
      "Input sentence: 728*489 Decoded sentence: 319964 Expected decoded sentence: 355992\n",
      "\n",
      "Input sentence: 925-11 Decoded sentence: 105 Expected decoded sentence: 914\n",
      "\n",
      "Input sentence: 382/639 Decoded sentence: 0.65555 Expected decoded sentence: 0.59781\n",
      "\n",
      "Input sentence: 372+946 Decoded sentence: 1255 Expected decoded sentence: 1318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- 1) Explain the interest in using teacher forcing during training. What is specific about this process?\n",
    "<span style=\"color:green\">\n",
    "Teacher forcing means that, at each timestep, we provide the previous correct token to be decoded to the decoder. In case we did not use it the prediction would have been provided. What is interesting with this process is it helps stabilizing training by focusing updates on wrong weights' states leading to actual misanswers from the network, not weights in right state which would have provided correct answer but for being given the correct input.\n",
    "</span>\n",
    "- 2) Describe step by step how the encoder-decoder couple works in this case (~ 5-10 lines)\n",
    "<span style=\"color:green\">\n",
    "There are $2$ symmetric networks, $2$ LSTMs, that have similar purposes. The first one, the encoder, processes vectors, $1$ at a time, and outputs a vector, $h_{t}^{enc}$. The position in vector space of $h_{t}^{enc}$ tells the decoder which token to predict first and contains information about all the vectors that have been processed. Thus at time $t$ there are $2$ choices: either provide $h_{t}^{enc}$ to the decoder so it knows which $1^{st}$ token to decode or process the next intput vector and produce $h_{t+1}^{enc}$.\n",
    "The final $h_{T}^{enc}$ is provided to the decoder along with the GO token. Position of $h_{T}^{enc}$ and GO token combined lead to a $h_{0}^{dec}$ vector to be produced, used as input by a fully connected layer to predict the first decoded token $\\hat{y}^{0}$. We iterate over this process, only instead providing $h_{t-1}^{dec}$ and true $\\hat{y}^{t-1}$ as input, until it predicts the $\\text{<EOS>}$ decoded token.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- 1) Describe how the attention mechanism works in the seq2seq setting (~ 5-10 lines)\n",
    "<span style=\"color:green\">\n",
    "Attention mechanism works by being able to focus on a specific subsequence in a long sequence to predict the right token at some timestep. That means not having to rely solely on final $h_{T}^{enc}$ to predict the whole decoded sequence, but rather recombining and weighing all the $h_{t}^{enc}$ at each decoding step to focus those related to the prediction.\n",
    "At each decoding step, a scalar product is performed between $h_{t}^{dec}$ and all the $h_{t}^{enc}$. This gives a similarity measure between $h_{t}^{dec}$ and each $h_{t}^{enc}$. A softmax is applied to this vector to rescale the similarity coefficients and make them sum to $1$. This way we can use them to compute a mean $h^{enc}$ vector to be used for prediction that allows the network to focus on some input tokens by making some coefficient relatively much greater than the others. Mean $h^{enc}$ vector is then computed and followed by $tanh$ operation to reduce vector input space of next operation. Final step is a softmax fully connected layer over the $tanh$ vector for prediction of the next decoded token. Applying attention mechanism involves iterating over this for each decoding timestep.\n",
    "</span>\n",
    "- 2) Compare the perfomances of your model at inference time with and without attention mechanism. Do you see noticeable differences? Why?\n",
    "<span style=\"color:green\">\n",
    "In this example, no noticeable difference is to be found between the performances of the $2$ different implementations, with and without attention mechanism. Also some quick visualization tells us that the network does not really focus much on part of the input to predict $1$ decoded token at a time. The reason for that is the encoding-decoding problem here is specific in the way that almost all input tokens are involved in producting each output token.\n",
    "</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
